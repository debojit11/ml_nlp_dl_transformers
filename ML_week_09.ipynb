{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSy5paryjoZx8xCtlEoR3M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debojit11/ml_nlp_dl_transformers/blob/main/ML_week_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ Week 9 ‚Äì Model Evaluation Techniques (Precision, Recall, F1 & More)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "QXQha_L5wVF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß≠ **Why Accuracy Isn‚Äôt Enough**"
      ],
      "metadata": {
        "id": "Jkwn4cpMwYpx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy can be misleading, especially when classes are imbalanced.\n",
        "\n",
        "> Imagine a spam detector where 95% of messages are ham.  \n",
        "> A model that always predicts \"ham\" gets **95% accuracy**, but it‚Äôs useless!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "rALo19sWwb3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **‚öñÔ∏è Core Metrics You Must Know**"
      ],
      "metadata": {
        "id": "JZ-twVn2weGb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "| Metric      | What it Measures                             | Good For                             |\n",
        "|-------------|----------------------------------------------|--------------------------------------|\n",
        "| **Precision** | Of predicted positives, how many are correct? | Spam filters (avoid false alarms)    |\n",
        "| **Recall** | Of actual positives, how many did we catch?   | Medical diagnosis (avoid misses)     |\n",
        "| **F1 Score**| Balance between Precision and Recall         | Most NLP tasks (balanced need)       |\n",
        "| **AUC-ROC** | Area under ROC curve ‚Äì model separates classes | General classifier performance       |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "WpY4sZKHwhPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **‚ú® Intuition: Precision vs Recall**"
      ],
      "metadata": {
        "id": "jOa_0dZoxAW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **Precision** = How **precise** your model is when it says \"positive\"  \n",
        "  _(Low precision = many false alarms)_\n",
        "\n",
        "- **Recall** = How many real positives you **remembered** to catch  \n",
        "  _(Low recall = missed many true cases)_\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "9E38qbGWxa1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **üéØ F1 Score = The Sweet Spot**"
      ],
      "metadata": {
        "id": "j_DsX4f5xdLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The **F1 Score** is the **harmonic mean** of precision and recall:\n",
        "\n",
        "$$\n",
        "F1 = 2 \\times \\frac{precision \\times recall}{precision + recall}\n",
        "$$\n",
        "\n",
        "> Use F1 when you care equally about Precision & Recall.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "tPw9XwhkxgBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **üìâ Confusion Matrix**"
      ],
      "metadata": {
        "id": "a0YjGhnOxkHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It‚Äôs the base for all classification metrics:\n",
        "\n",
        "|               | Predicted Positive | Predicted Negative |\n",
        "|---------------|--------------------|--------------------|\n",
        "| Actual Positive | ‚úÖ TP               | ‚ùå FN               |\n",
        "| Actual Negative | ‚ùå FP               | ‚úÖ TN               |\n",
        "\n",
        "From here we get:\n",
        "- Accuracy\n",
        "- Precision\n",
        "- Recall\n",
        "- F1\n",
        "- Specificity, etc.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ehdp1azWxobR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **üìà ROC Curve & AUC**"
      ],
      "metadata": {
        "id": "XEfptYcMxrox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "ROC = Receiver Operating Characteristic\n",
        "\n",
        "- Plot **True Positive Rate (Recall)** vs **False Positive Rate**\n",
        "- **AUC** = Area Under the Curve (Higher = Better)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "kEAK42ORxvMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **üß† When to Use What?**"
      ],
      "metadata": {
        "id": "_UQ5IShux7GN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Situation                          | Focus On         |\n",
        "|-----------------------------------|------------------|\n",
        "| Spam detection                    | Precision        |\n",
        "| Disease screening (catch all)     | Recall           |\n",
        "| Balanced NLP classification task  | F1 Score         |\n",
        "| General classifier performance    | AUC-ROC          |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "l6Th8mAkx9Pb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You now know **how to evaluate models beyond just accuracy**.  \n",
        "This will **sharpen your intuition** and help you **compare models fairly** ‚Äî especially on real-world NLP tasks üß†üìä\n",
        "\n",
        "‚û°Ô∏è Next week: we‚Äôll shift to **unsupervised learning** with **K-Means Clustering** üîç  \n",
        "Let‚Äôs see how machines group similar text without any labels!"
      ],
      "metadata": {
        "id": "0ThwkRwdx_Tc"
      }
    }
  ]
}