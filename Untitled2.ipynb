{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAyz8dcCP7tlGdUIRl9abU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debojit11/ml_nlp_dl_transformers/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìö Week 19 ‚Äì Advanced RAG: Hybrid Retrieval & Evaluation Metrics\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Objectives\n",
        "\n",
        "This week, you'll:\n",
        "- Understand **Hybrid Retrieval** (dense + sparse)\n",
        "- Implement BM25 + FAISS hybrid retrievers\n",
        "- Combine retrieval scores\n",
        "- Evaluate RAG with simple metrics (e.g., context recall)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "x50UK9ot5kCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† What is Hybrid Retrieval?\n",
        "\n",
        "**Dense retrieval** (like FAISS + embeddings):\n",
        "- Captures semantic meaning\n",
        "- Misses exact keyword matches sometimes\n",
        "\n",
        "**Sparse retrieval** (like BM25):\n",
        "- Captures exact token matches\n",
        "- Misses semantic similarities sometimes\n",
        "\n",
        "üëâ **Hybrid** combines the best of both worlds:\n",
        "- Use both scores together\n",
        "- Boost both precision and recall\n",
        "\n",
        "---\n",
        "## üß† Why Hybrid Retrieval?\n",
        "\n",
        "Dense models (like Sentence Transformers):\n",
        "- Good at semantic similarity\n",
        "- Miss exact keyword matches\n",
        "\n",
        "Sparse models (like BM25):\n",
        "- Good at exact keyword matching\n",
        "- Miss semantic paraphrases\n",
        "\n",
        "**Hybrid Retrieval = Dense + Sparse ‚Üí Better Recall**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "QeDLVCcA5nH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîß Setup"
      ],
      "metadata": {
        "id": "XRp1NbHL6HLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q faiss-cpu rank_bm25 rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgIJYTsY6Hp6",
        "outputId": "a290d99f-7345-4466-d864-17edd85e86a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "from rank_bm25 import BM25Okapi\n",
        "from rouge_score import rouge_scorer\n",
        "import faiss\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "y2hdnpQ66L9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "3V3VVSxz6TDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìÑ Define the Corpus"
      ],
      "metadata": {
        "id": "CZ7As_-w6VoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    \"Transformers revolutionized NLP with attention mechanisms.\",\n",
        "    \"BM25 is a ranking function used by search engines.\",\n",
        "    \"Deep learning models require large datasets for training.\",\n",
        "    \"FAISS allows efficient similarity search over vector databases.\",\n",
        "    \"The Eiffel Tower was completed in 1889.\",\n",
        "    \"PyTorch and TensorFlow are popular deep learning frameworks.\"\n",
        "]"
      ],
      "metadata": {
        "id": "zAMwuV4X6Xo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üîç Create Dense Retriever (FAISS + SentenceTransformer)"
      ],
      "metadata": {
        "id": "7b-Ym3Mb6bes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "dense_embeddings = dense_model.encode(corpus, convert_to_numpy=True)\n",
        "dense_embeddings = dense_embeddings / np.linalg.norm(dense_embeddings, axis=1, keepdims=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534,
          "referenced_widgets": [
            "0654e513e2da407c9510ad29fc203c6d",
            "d5e78d2e536442b19d6721d1bc3e30a4",
            "e38087f00c0440fdbbbc44184ce8bb0e",
            "2586442903c74f1db5f68bebc5c0bf3a",
            "476b901c47d44b6ba2b5d33e37c87ffc",
            "46d4fe9eba5147a58345ec199bc7873a",
            "eca6dea0852a4a96aefa7cd3dd5e9823",
            "5091041bd4104fe09c6a9ef2ba058bf0",
            "1d323943b1b8482fa5dba3e9cc1797a3",
            "8a3476ecb70f444ebacf011e85adf19c",
            "204c0afd590d4c16837ed720b118ab8a",
            "3f40cb25929e46e4ae8d6d70bb103a29",
            "07e7e01529e848069b4bb9a64d9d7818",
            "e985de8fb4604be6a9bc34c1f762ebbf",
            "efbc982bd9b24d0cbdfded4dbf349a62",
            "31756a9cc2644d47be1156923733a242",
            "5de0c9a70de545d29b72451d0aa23809",
            "b2edb4bacc6b461b9dcb36f63d093e9e",
            "8fefe87a2b6d40ebb2a38ef8a1b1cf1b",
            "c0be5fc7fe824ccfa180dd26a4fdc7bc",
            "9d282df4c62546a3b401872f42a6f7d2",
            "d9f6c1282320456eb269781f11a36be4",
            "ecf32e12415f462585509881dae836d2",
            "bd9a419c8adf46edae4396a02066eb69",
            "5b9c6efcb3d84cf490abc94e0e88fb77",
            "2e360ef32521443ebffd2c50e44964aa",
            "9b6f9131201f4e58a17b10aaaa29ccf9",
            "49ce1a45b8984342b24e8bed9c78d3e3",
            "823cdf0c1cd94c39900775c400b49bd2",
            "1a0412e92aae4cebb2e6623e3f7f649d",
            "25a4db6c8a554f068b3bc866d0c27f9f",
            "b680afec7f43414eba2ad2d5cf7fd5ad",
            "45ad355992b644b0b889ec30fd7c62e9",
            "90d4259b8b144a859716e05d8238ee95",
            "7fd382c8da9747da81fa92df583442f3",
            "9c41f237d74b4154a9f008d3561d2b88",
            "a43c6671f18646e0bc22ac449f899419",
            "ac1aef80401944969538697901cf1a2b",
            "21cc63ad40c34e89a686a016e4425c18",
            "ecef95091c124bc19fbc4f055ad14fec",
            "17a74cc09ac54b0394648a82e8211a13",
            "9ec52f4f8fb24992972b46e54f1ac66e",
            "ac47e63bcf29436eb374dd4ba52e6a1e",
            "efec72f8387f4545b7d01fe4301dab83",
            "d28775b22c9d4364a14929e0eb7d38ba",
            "c5c4c53e29f8451b9603a72b4fba4650",
            "93faf744dd4d464d8a09ee9e5eacfae3",
            "e0750ecbe67d4ce682247066fc540c04",
            "13d6a37c82b5418d9c89a9d7ae3f2c45",
            "6a8d7e5c59e749a197539e08ecff9ebf",
            "c1939b6340ad4165bd72ada5367d486e",
            "3183523dec34407482d0b1d1d9d7d132",
            "13c47d2ea2014e95a52cab486c77c906",
            "8fff67dfbc4243f8aa3583e725b78e3e",
            "2439731b2fd64c3589528b3207d4f1db",
            "f1e205450f1c4f02b5275902086339be",
            "8fe0035381f14d4590bf7b22780901d9",
            "6bd89ec3db95406288c77a67d5731d0c",
            "c28edae1e7a54aeb8db714b47f4462a8",
            "0f082134e73c42939e3fc50182e3d52e",
            "97aa60806397488f961447b7547398a6",
            "35c3fa84a33040bea57981e820a6942c",
            "68060bf9255b4547add34d90aa31b2ed",
            "2fb5d0c8246f460da909496b937ef23a",
            "eafc82fe4de84338b90748b1bf9474bb",
            "c65fefd0aca748038cd2ff76af7e35b1",
            "19a05a81ace942dd80cb4d1c316ae425",
            "f93b9918e8bd43fea16a058f22cf3671",
            "aa0b43df3f044618b6ae64c41935cb18",
            "ff655073b7f64df4a9dc75c6edca1adc",
            "4865c16a66a643ceba11273c3215fcce",
            "8ec287723ef844f593881990660b9aa2",
            "6ac37528ec5143afb278deae373967d5",
            "d51fa98fa42d47ad968704c1fdf0ebdf",
            "abefb74629f74ed9b7a7e02cc93138e1",
            "d990d7cc128b49d2a35a77ea97d15d61",
            "2cd256b296aa4d499c0bf37146d735d6",
            "4d6ae285736043c99fbd1a717f8201f1",
            "dbe884f1017e44aaabccdbed6ceacb61",
            "cb0c041b4ea04f9b803c0049e93ee203",
            "11dc815ec7fa4494b5d6d797a311145a",
            "f5850dafd4364241ab5a11cfaf6a4114",
            "ae87169ce6f6448da83aa8bd757cb36d",
            "b035767de698480cb891436119e25b58",
            "c0ecda2849fc40fe85341d6fe9f55111",
            "400ec024fd1245508b2c69db1ee0cc85",
            "a461763e7aab41e6b3292c64b9eb3db4",
            "b9ff8e28b9d042bfad13715741d07435",
            "46c159bd2675448a8d077bd72b70b8c7",
            "2bdad66fe72a4d539ea32b2522d623bd",
            "bda450eaafe34253b028f1d84b268a45",
            "5d3e40a1d97443e89f7a920d0640a84d",
            "a5a6c9f6d021409eb79ac404ed443535",
            "ad8cac4facef4194b109ea1dfd7d94dd",
            "3ae7fbb6d2f9443fb45d2b563d0cc1b1",
            "431e40c8c39c43ddb27ba369f8772d11",
            "6e9475544684421bbc474986d31d911f",
            "301f7151b7a2482eb223ffa9bf7b4986",
            "7b3d50b6e31747d5b58f6e442405586a",
            "1efa1028223747568e3b9eeb2064c948",
            "964dd5a0c61746fe8287e48f47d22245",
            "21b6f21aa97b4f22a295df1f44938314",
            "7bb55fc0622e4d0185e491058c5d6b96",
            "34853c67419c4de884e4856af5b74c1d",
            "70be7a87292e4e8bb84d1a20f294aa64",
            "8df2bbb85a0f415b8fc94947f6ea8c6a",
            "05df13a608c046be9415c4ed1c6d8b4a",
            "c28cab6d7aa6402592c5839585e7894c",
            "4e797e06858342ab8c2a8e36007e8f59",
            "fc96c1bcb9874aab8b1036c2d431a126",
            "2562d38d0979474ab5084d0bea5f7042",
            "39bbfa34c1164593a175a44c8b421052",
            "cebe612e983344b7b088e53d7c9f2dde",
            "9bcdf8d877884963a3949641e32ccad0",
            "06de44e84ef34971be180d172501d479",
            "c5e18c775e254213bf886208f268d350",
            "bc6cacc9b61440788a697fdc7e38fbf3",
            "73b6a032db6744859c8d189932baa56b",
            "339d845d2aff4eefb8669f4c00c3926d",
            "5f66a4e8b915482f98846d44fe943239",
            "05c56df902e544feb88bee4bbc93e71e"
          ]
        },
        "id": "xGGf9GY66Z6G",
        "outputId": "6e1f7c44-4480-448f-d1b3-dcffbe948cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0654e513e2da407c9510ad29fc203c6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f40cb25929e46e4ae8d6d70bb103a29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ecf32e12415f462585509881dae836d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90d4259b8b144a859716e05d8238ee95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d28775b22c9d4364a14929e0eb7d38ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1e205450f1c4f02b5275902086339be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19a05a81ace942dd80cb4d1c316ae425"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d6ae285736043c99fbd1a717f8201f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46c159bd2675448a8d077bd72b70b8c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1efa1028223747568e3b9eeb2064c948"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2562d38d0979474ab5084d0bea5f7042"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dense_index = faiss.IndexFlatIP(dense_embeddings.shape[1])\n",
        "dense_index.add(dense_embeddings)"
      ],
      "metadata": {
        "id": "UBMHY7vG6d3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dense_retrieve(query, k=3):\n",
        "    query_embedding = dense_model.encode([query], convert_to_numpy=True)\n",
        "    query_embedding = query_embedding / np.linalg.norm(query_embedding)\n",
        "    D, I = dense_index.search(query_embedding, k)\n",
        "    return [(corpus[i], float(D[0][idx])) for idx, i in enumerate(I[0])]"
      ],
      "metadata": {
        "id": "hsJPZA-56grG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "3qmLgVR46mnd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîç Create Sparse Retriever (BM25)"
      ],
      "metadata": {
        "id": "eCHK6Ef96pRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_corpus = [doc.lower().split() for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)"
      ],
      "metadata": {
        "id": "jCFGnSkK6k_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sparse_retrieve(query, k=3):\n",
        "    tokenized_query = query.lower().split()\n",
        "    scores = bm25.get_scores(tokenized_query)\n",
        "    top_k = np.argsort(scores)[::-1][:k]\n",
        "    return [(corpus[i], float(scores[i])) for i in top_k]"
      ],
      "metadata": {
        "id": "rbGgkTxM6sP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "sSFa1Was6vfu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß© Combine Dense + Sparse ‚Üí Hybrid Retrieval"
      ],
      "metadata": {
        "id": "Y4Qp82aO6wRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hybrid_retrieve(query, k_dense=3, k_sparse=3, alpha=0.5):\n",
        "    dense_results = dense_retrieve(query, k=k_dense)\n",
        "    sparse_results = sparse_retrieve(query, k=k_sparse)\n",
        "\n",
        "    scores = {}\n",
        "\n",
        "    # Add dense scores\n",
        "    for doc, score in dense_results:\n",
        "        scores[doc] = scores.get(doc, 0) + alpha * score\n",
        "\n",
        "    # Add sparse scores\n",
        "    for doc, score in sparse_results:\n",
        "        scores[doc] = scores.get(doc, 0) + (1 - alpha) * score\n",
        "\n",
        "    # Sort combined scores\n",
        "    ranked_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [doc for doc, _ in ranked_docs[:k_dense]]"
      ],
      "metadata": {
        "id": "AXlFGCCh6t1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üß™ Test Hybrid Retriever\n"
      ],
      "metadata": {
        "id": "ZXltRcdR8Lpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is BM25?\"\n",
        "docs = hybrid_retrieve(query)\n",
        "\n",
        "print(\"üîç Query:\", query)\n",
        "print(\"üìö Retrieved Documents:\")\n",
        "for doc in docs:\n",
        "    print(\"-\", doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jITGOFE8J7_",
        "outputId": "884df621-6700-47b8-d9cd-c556e68fd617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Query: What is BM25?\n",
            "üìö Retrieved Documents:\n",
            "- BM25 is a ranking function used by search engines.\n",
            "- PyTorch and TensorFlow are popular deep learning frameworks.\n",
            "- Deep learning models require large datasets for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ü§ñ Generator: T5 for Answer Generation\n"
      ],
      "metadata": {
        "id": "k4Q7vGj78TRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352,
          "referenced_widgets": [
            "aa7b292589bb43929bb764495232a099",
            "c73c5d3983604475a17a33f41bd162ed",
            "73cf87ee07bf49d1ab55b4973cca21bc",
            "50474f5d5ba1484d8cd54e6709c370d5",
            "480b71dfcd234b9c933787ddbae7adfb",
            "139c77de8adb4bb89533dc293bd0bdfe",
            "0a88885397df4c849608b09b836de371",
            "4fd2e820b4764d64bbe31ca1b3703c27",
            "52c1bc1dc8f44023a2965cc84ffd000d",
            "1e9104967ddd4f08a0ee8c34d133222a",
            "10234ad9316d4087b7ccf02364c97a8f",
            "2c463ccdbb9a400f83e5f4abafaef52a",
            "02d1939d7b36440aba362c492f8386e1",
            "e14e12c7cc2441d99cce8c81ad3656a7",
            "1d8d33d52da44b7f97760da675e34b03",
            "6e6aa48d45674d038fccf7419890f745",
            "1202c17f7da54d469531908347441734",
            "094e8a58e7ef48309aeef0b2249dbcfb",
            "68b141f18d304fbd8f49c200e4b86c05",
            "d723321393834567b31d35c5b8b5dc90",
            "accc6a6a15164a688922374d83c7521b",
            "8c6ad5720aaa413f92621eebd5b58a2a",
            "1472b61258f245e28e669902e2df62a1",
            "b4831f1a4fdd4624bc4a6260b23e95b9",
            "974dedba190e49a0974f30b076da673f",
            "ce6e29b1b95443b794b013b886abd11d",
            "f50926a012f74efcb4b179b155f08568",
            "54b1036f9fb140769b374db74626e410",
            "a80d2939bb49498b8a0a7daf1c7117b1",
            "29486f62e54c49a2b607aea2e20bad74",
            "6896c01e41b04d18a267617e6f7fe357",
            "efefc784bc9a4f43bb491837d14ec005",
            "36a62b7477b74e5bad63c2e90d6f8b08",
            "e67b7faec94448a09106238562d65915",
            "5eb38d336949494fba99ae5ff8997690",
            "1954c45bf3404789806e977e1db5b4df",
            "8507b25949e945acae1205188663d235",
            "0f40a06f176e4c29820713db499fdc33",
            "666dc5e07fe34729a98ede443cb8f97f",
            "93511bd829b14642afc23a83650015a8",
            "8c697060f5084aed9abac79ac2bb0f8a",
            "fdcf76b447404c699cd0e4bfeede4795",
            "ae0349e02fc846c5966b80e40e68240c",
            "cce408fc81164a8eb8ec33683e47c7af",
            "75961cb9bbc04198af0c65727e7b1d84",
            "69fe172964cd4b1cb617e1d196254961",
            "536889555d544afbb010d6ac99ebf606",
            "673c1c2c9c2f42c18e2cee57f38e9b9f",
            "2cd61545a67c4fd6a7b952bf5c415b55",
            "47fa1325617e4a9fbf462b6c92c45fae",
            "5a49137b574648a1909a684b01390d32",
            "2b3f3bcf283c4a71822b7c506afa54d5",
            "19b6dfc2ffd54c1d8f2cec3ad32a00c0",
            "83bc33bf1a6046b9a41fe265faeb41a9",
            "9ab1a2f86d3b4a18a553eb5ecc23418a",
            "6a9b4c5fa8ed48cba0466e79fd28b945",
            "72992a908751450ca38fa39cf56e75a8",
            "0e8ff876d24c4b7ea10c7e4cb0f50b82",
            "eed18af206a44543a4f1985797ddc3dc",
            "db3bf525318d4a5eb677bcaa52c1ad84",
            "95c38d2dff6c4d87b825cf1689e19e61",
            "fc4437a8fbfb472bacf6689917100529",
            "638922bfd59e478b88a55474988d6d13",
            "af709530f59b4555bd3dbbdb5b9cc8a8",
            "f3c205344c7a48da9c9c69c2ca9bf6d3",
            "c4651ea73fb34e448cd9f9aaaa289f5a",
            "77b99923e76242c5bf59a3945d13973c",
            "cfd3fbcecea54c1f8d407201111b3913",
            "13645387ac7b45a49e8d7da571f4d066",
            "f2ad633c4cf44043a602819da95d76dc",
            "7484898052234c1b8ddcac18700fd981",
            "38a13297e88f4fac9645f2eeb8d53dd4",
            "731be5a3e55b4962a08aa844dd960399",
            "87dad566a715405285e6a3e1769bc655",
            "420d842430f84bb2a33c14a90c7f8b71",
            "027ed0e8ef7b450d9d00120c250de391",
            "99abfa67966d44b5a55b8574fbef2bf3"
          ]
        },
        "id": "kmwNVLmN8N_Y",
        "outputId": "4afedeac-8c04-4d88-f6f7-1e44aa9bde7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa7b292589bb43929bb764495232a099"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c463ccdbb9a400f83e5f4abafaef52a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1472b61258f245e28e669902e2df62a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e67b7faec94448a09106238562d65915"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75961cb9bbc04198af0c65727e7b1d84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a9b4c5fa8ed48cba0466e79fd28b945"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77b99923e76242c5bf59a3945d13973c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(query, retrieved_docs):\n",
        "    context = \" \".join(retrieved_docs)\n",
        "    prompt = f\"question: {query} context: {context}\"\n",
        "    output = generator(prompt, max_length=64, do_sample=False)\n",
        "    return output[0]['generated_text']"
      ],
      "metadata": {
        "id": "wgtzXMfx8VSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üß™ End-to-End Hybrid RAG Demo\n"
      ],
      "metadata": {
        "id": "ooiY3cia8cD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"When was the Eiffel Tower completed?\"\n",
        "retrieved_docs = hybrid_retrieve(query)\n",
        "generated_answer = generate_answer(query, retrieved_docs)\n",
        "\n",
        "print(\"üì• Query:\", query)\n",
        "print(\"üìö Context:\")\n",
        "for doc in retrieved_docs:\n",
        "    print(\"-\", doc)\n",
        "print(\"üß† Generated Answer:\", generated_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Wkc94NV8Zlg",
        "outputId": "9a806cc2-070a-4ef0-d9ea-bba23fc2e2da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Query: When was the Eiffel Tower completed?\n",
            "üìö Context:\n",
            "- The Eiffel Tower was completed in 1889.\n",
            "- BM25 is a ranking function used by search engines.\n",
            "- FAISS allows efficient similarity search over vector databases.\n",
            "üß† Generated Answer: 1889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üìè How to Evaluate RAG Quality\n"
      ],
      "metadata": {
        "id": "S7mSunJ28jgh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You care about:\n",
        "- Retrieval Recall: Did you fetch good context?\n",
        "- Generation Accuracy: Was the answer correct?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "sxrZq0Wq8oKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Evaluate Generated Answer with ROUGE and BLEU\n"
      ],
      "metadata": {
        "id": "HRs-IQLY8mRJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úèÔ∏è Define References and Compute Scores"
      ],
      "metadata": {
        "id": "AzdCq_Lz8rGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground truth reference\n",
        "reference = \"The Eiffel Tower was completed in 1889.\""
      ],
      "metadata": {
        "id": "kZFeK8XY8vZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicted/generated text\n",
        "prediction = generated_answer"
      ],
      "metadata": {
        "id": "1IpN1Ekr8v17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
        "scores = scorer.score(reference, prediction)"
      ],
      "metadata": {
        "id": "QIwe-h2U8xUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üîé ROUGE Scores:\")\n",
        "for metric, score in scores.items():\n",
        "    print(f\"{metric}: Precision={score.precision:.2f}, Recall={score.recall:.2f}, F1={score.fmeasure:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1Aa0DZL8zDk",
        "outputId": "5fc87afd-4aaa-474d-8563-5b0d83795274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîé ROUGE Scores:\n",
            "rouge1: Precision=1.00, Recall=0.14, F1=0.25\n",
            "rouge2: Precision=0.00, Recall=0.00, F1=0.00\n",
            "rougeL: Precision=1.00, Recall=0.14, F1=0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Notes on Evaluation\n",
        "\n",
        "---\n",
        "\n",
        "### üìä ROUGE Score Summary\n",
        "\n",
        "| Metric   | Precision | Recall | F1 Score |\n",
        "|----------|-----------|--------|----------|\n",
        "| ROUGE-1  | 1.00      | 0.14   | 0.25     |\n",
        "| ROUGE-2  | 0.00      | 0.00   | 0.00     |\n",
        "| ROUGE-L  | 1.00      | 0.14   | 0.25     |\n",
        "\n",
        "---\n",
        "\n",
        "### üîç Key Observations\n",
        "\n",
        "- **ROUGE-1**:\n",
        "  - Very high precision (1.00) but low recall (0.14).\n",
        "  - This suggests the model generated some correct keywords but missed many expected ones.\n",
        "  - Happens often when answers are correct but shorter or phrased differently.\n",
        "\n",
        "- **ROUGE-2**:\n",
        "  - Zero overlap in bigrams (2-word phrases).\n",
        "  - Indicates that exact phrasing between the generated text and the reference answer did not match.\n",
        "  - Common for abstractive models or rephrasings.\n",
        "\n",
        "- **ROUGE-L**:\n",
        "  - Similar to ROUGE-1 because of short answers.\n",
        "  - Captures matching sequences but still limited by recall.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Interpretation for Short Factual Answers\n",
        "\n",
        "- ROUGE can **underestimate quality** if the generated text is correct but worded differently.\n",
        "- **Manual inspection** is necessary for small, factual answers.\n",
        "- High precision but low recall often means \"correct but incomplete\" or \"correct but differently phrased.\"\n",
        "\n",
        "---\n",
        "\n",
        "### üöÄ Tips for Evaluation\n",
        "\n",
        "- Always combine **automatic metrics** with **manual review**.\n",
        "- For short answers, consider adding:\n",
        "  - **Exact Match (EM)**: 100% if the answer matches exactly.\n",
        "  - **BLEU**: Measures n-gram overlaps, used in translation.\n",
        "  - **BERTScore**: Embedding-based semantic similarity (better for free-text generations).\n",
        "\n",
        "---\n",
        "\n",
        "üìö **Summary**:  \n",
        "Use ROUGE carefully. It works best for longer generations like summaries.  \n",
        "For RAG-style short factual answers, rely on a **combination of ROUGE, BLEU, EM, and manual checks**.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "pV39KQjB9XqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìù Exercises\n",
        "\n",
        "1. Try varying `alpha` in hybrid retrieval from 0.2 to 0.8.  \n",
        "   ‚Üí Does generation quality change?\n",
        "   \n",
        "2. Test using larger corpus (Wikipedia sections) and see if retrieval needs scaling.\n",
        "\n",
        "3. Compare RAG performance:\n",
        "   - Dense only\n",
        "   - Sparse only\n",
        "   - Hybrid\n",
        "   \n",
        "4. Fine-tune a SentenceTransformer model on custom domain (advanced).\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "K3Dlr_lb9dNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚û°Ô∏è Coming up next: **Week 20 ‚Äì RAG CapstoneüöÄ**"
      ],
      "metadata": {
        "id": "gbTLLL4p9d1w"
      }
    }
  ]
}