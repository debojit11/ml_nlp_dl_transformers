{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCkNLu/PtLZp2NvGW8qpqm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debojit11/ml_nlp_dl_transformers/blob/main/ML_week_11_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìö Week 11.5 ‚Äì Understanding Text Vectorization (CountVectorizer & TF-IDF)\n",
        "---\n"
      ],
      "metadata": {
        "id": "Qqh264YM-7t-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ü§î Why Vectorize Text?\n",
        "Machines work with **numbers**, not words.\n",
        "Text vectorization = converting **raw text ‚Üí numerical features**  \n",
        "This is the **first step** in almost every NLP pipeline.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "hudWRTd8_LKY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß∞ Common Vectorization Methods\n",
        "| Method            | What it does                              | Notes |\n",
        "|-------------------|--------------------------------------------|-------|\n",
        "| CountVectorizer   | Counts how often each word appears         | Simple, can be sparse |\n",
        "| TF-IDF Vectorizer | Weighs word frequency + how rare it is     | Reduces weight of common words |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "uHmSVCIr_W-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úèÔ∏è Example: CountVectorizer\n",
        "```python\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "docs = [\"I love NLP\", \"NLP is cool\", \"I love coding\"]\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(docs)\n",
        "print(\"Vocabulary:\", vectorizer.get_feature_names_out())\n",
        "print(\"Count Matrix:\\n\", X.toarray())\n",
        "```\n",
        "Output:\n",
        "```\n",
        "Vocabulary: ['coding' 'cool' 'is' 'love' 'nlp']\n",
        "Count Matrix:\n",
        " [[0 0 0 1 1]\n",
        " [0 1 1 0 1]\n",
        " [1 0 0 1 0]]\n",
        "```\n",
        "\n",
        "Each row = a sentence  \n",
        "Each column = word frequency  \n",
        "Words like \"I\" are removed automatically if you use `stop_words='english'`.\n",
        "\n"
      ],
      "metadata": {
        "id": "KRHZeAFf_ewJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìè Example: TF-IDF Vectorizer\n",
        "TF = Term Frequency\n",
        "IDF = Inverse Document Frequency\n",
        "\n",
        "```python\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(docs)\n",
        "print(\"Vocabulary:\", vectorizer.get_feature_names_out())\n",
        "print(\"TF-IDF Matrix:\\n\", X.toarray())\n",
        "```\n",
        "\n",
        "Output: (approximate values)\n",
        "```\n",
        "Vocabulary: ['coding' 'cool' 'is' 'love' 'nlp']\n",
        "TF-IDF Matrix:\n",
        " [[0.     0.     0.     0.7071 0.7071]\n",
        " [0.     0.7071 0.7071 0.     0.    ]\n",
        " [0.7071 0.     0.     0.7071 0.    ]]\n",
        "```\n",
        "\n",
        "TF-IDF **downweights common words** across documents (like \"nlp\" here). It's **better for distinguishing informative words** than raw counts.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZXq4Jx4g_oay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚öñÔ∏è CountVectorizer vs TF-IDF\n",
        "| Feature | CountVectorizer | TF-IDF |\n",
        "|---------|----------------|--------|\n",
        "| Simplicity | ‚úÖ Very simple | ‚ùå Slightly more complex |\n",
        "| Common words | ‚úÖ Weighted equally | ‚úÖ Penalized (IDF) |\n",
        "| Rare words | ‚ùå No boost | ‚úÖ Boosted by IDF |\n",
        "| Good for | Naive Bayes, baseline models | SVM, Logistic Regression |\n",
        "\n"
      ],
      "metadata": {
        "id": "nL_Xmtad_sVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚ú® Real Use Case in NLP\n",
        "Before we fed our SMS spam data to:\n",
        "* Logistic Regression\n",
        "* Random Forest\n",
        "* KNN\n",
        "* SVM\n",
        "\n",
        "We used `TfidfVectorizer` to turn raw messages into **numerical vectors**.\n",
        "Now you understand **what those numbers represent**! üìä\n",
        "\n"
      ],
      "metadata": {
        "id": "DTUPC5Si_xfU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß™ Bonus: N-grams\n",
        "```python\n",
        "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
        "X = vectorizer.fit_transform([\"I love NLP\", \"NLP is fun\"])\n",
        "print(\"N-grams:\", vectorizer.get_feature_names_out())\n",
        "print(X.toarray())\n",
        "```\n",
        "\n",
        "Output:\n",
        "```\n",
        "N-grams: ['fun' 'i' 'i love' 'love' 'love nlp' 'nlp' 'nlp is' 'is']\n",
        "```\n",
        "\n",
        "`ngram_range=(1,2)` means unigrams + bigrams. Useful for capturing **phrase-level meaning** (e.g., \"not good\").\n",
        "\n"
      ],
      "metadata": {
        "id": "jZgfxhyY_16k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Summary\n",
        "* Vectorization = turning text into **number vectors**.\n",
        "* `CountVectorizer`: simple, fast.\n",
        "* `TF-IDF`: smarter, reduces noise from common words.\n",
        "* Used **before training** any ML model."
      ],
      "metadata": {
        "id": "W49lf_B8_7r8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîú Up Next: Week 12\n",
        "Now that your text is numerical, you're ready for **MLPs (Neural Networks)** to learn **deeper representations** üî• Let's dive into deep learning next!"
      ],
      "metadata": {
        "id": "COdk01rQ_-DV"
      }
    }
  ]
}