{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEtasTcrzu9HQ0fafr+PoF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debojit11/ml_nlp_dl_transformers/blob/main/TF_week_15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 15: Transformers & BERT (Modern NLP)"
      ],
      "metadata": {
        "id": "VygspGmFNIEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SECTION 1: Welcome & Objectives**"
      ],
      "metadata": {
        "id": "HRwt53rTNKg4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM_67h2-M_0X",
        "outputId": "195aa2a6-94ad-41bf-e6d2-8a10ed24940e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to Week 15!\n",
            "This week, you'll:\n",
            "- Understand the Transformer architecture\n",
            "- Learn how BERT works for NLP tasks\n",
            "- Use Hugging Face Transformers for real-world NLP\n"
          ]
        }
      ],
      "source": [
        "print(\"Welcome to Week 15!\")\n",
        "print(\"This week, you'll:\")\n",
        "print(\"- Understand the Transformer architecture\")\n",
        "print(\"- Learn how BERT works for NLP tasks\")\n",
        "print(\"- Use Hugging Face Transformers for real-world NLP\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SECTION 2: What Are Transformers?**"
      ],
      "metadata": {
        "id": "K9vNSyeaNUFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ü§ñ What Are Transformers?\n",
        "Transformers are deep learning architectures designed to handle **sequential data** like text.\n",
        "\n",
        "They use:\n",
        "- **Self-Attention** to relate all words to each other\n",
        "- **Positional Encoding** to retain order\n",
        "- A stack of **Encoder (BERT)** or **Decoder (GPT)** blocks"
      ],
      "metadata": {
        "id": "ioSowoZCNVlw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ Week 15 ‚Äì Transformers & BERT (Modern NLP)\n",
        "\n",
        "---\n",
        "\n",
        "## üîç Why Transformers?\n",
        "\n",
        "Traditional models (RNNs, LSTMs) process sequences **step-by-step**, which:\n",
        "- Slows down training\n",
        "- Makes it hard to capture long-range dependencies\n",
        "\n",
        "**Transformers** process all tokens **in parallel**, using **attention mechanisms** to focus on relevant words.  \n",
        "This enabled massive models like BERT, GPT, T5, etc.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "wOPCESzTOdNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SECTION 3: Self-Attention Intuition**"
      ],
      "metadata": {
        "id": "XJaeaErQNaax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß† Why Self-Attention?\n",
        "In traditional RNNs/LSTMs:\n",
        "- Information flows step-by-step (sequentially)\n",
        "- Hard to model long-range dependencies\n",
        "\n",
        "Transformers:\n",
        "- Each word attends to all others in parallel\n",
        "- Learn what to \"focus\" on during prediction\n",
        "\n",
        "Example:\n",
        "> \"The animal didn't cross the street because **it** was too tired.\"\n",
        "> \\--> What does **it** refer to? Self-attention helps figure that out."
      ],
      "metadata": {
        "id": "M0TXu5cnNdjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîó Core Idea: Self-Attention\n",
        "\n",
        "Self-attention helps the model learn **which words to attend to**, regardless of position.\n",
        "\n",
        "> \"The cat sat on the **mat** because it was **tired**.\"\n",
        "\n",
        "BERT knows ‚Äúit‚Äù refers to ‚Äúcat‚Äù because attention weights learn such relationships.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "IEoSzmrYOjYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each word attends to **all other words** in the sentence.\n",
        "This helps capture:\n",
        "- Context\n",
        "- Word relationships\n",
        "- Long-range dependencies\n",
        "\n",
        "$$\n",
        "\\text{Attention}(Q, K, V) = \\text{softmax}\\left( \\frac{QK^T}{\\sqrt{d_k}} \\right)V\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- Q = Query\n",
        "- K = Key\n",
        "- V = Value\n",
        "\n",
        "---\n",
        "\n",
        "### üì¶ Key Components\n",
        "\n",
        "| Component        | Role                                         |\n",
        "|------------------|----------------------------------------------|\n",
        "| Multi-head Attention | Captures relationships from different subspaces |\n",
        "| Positional Encoding | Adds order to the input tokens            |\n",
        "| Feed-Forward Layer | Transforms each token independently        |\n",
        "| Layer Norm + Residual | Helps in training deep layers           |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "noPShB7zPa2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìê Transformer Architecture\n",
        "\n",
        "A single **Transformer block** includes:\n",
        "- Multi-head Self-Attention\n",
        "- Layer Norm\n",
        "- Feedforward Layers\n",
        "- Positional Encoding\n",
        "\n",
        "Stack many such blocks ‚Üí Transformer model.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "nJ75A_hHOovD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SECTION 4: Load Pretrained BERT (Text Classification)**"
      ],
      "metadata": {
        "id": "JqXAh9tZNlyq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† What is BERT?\n",
        "\n",
        "**BERT = Bidirectional Encoder Representations from Transformers**\n",
        "\n",
        "It:\n",
        "- Uses only the **encoder** part of the Transformer\n",
        "- Reads text in **both directions**\n",
        "- Pretrained on:\n",
        "  - **Masked Language Modeling** (fill in the blanks)\n",
        "  - **Next Sentence Prediction** (understand relationships)\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "mUVS2FBcOzQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß± Encoder vs Decoder\n",
        "\n",
        "| Encoder (BERT)       | Decoder (GPT)       |\n",
        "|----------------------|---------------------|\n",
        "| Bidirectional        | Autoregressive       |\n",
        "| Looks at full context | Left-to-right only |\n",
        "| Ideal for classification, QA | Ideal for text generation |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "UxKHoDyVPm4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîß Using BERT via Hugging Face\n",
        "\n",
        "Hugging Face ü§ó Transformers makes it easy to use pretrained BERT models.\n",
        "\n",
        "```python\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "print(classifier(\"I love this movie!\"))\n",
        "```"
      ],
      "metadata": {
        "id": "VsRX2vx6O7ET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "rduhfNPsNnLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a simple sentiment analysis pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "result = classifier(\"Transformers are revolutionizing NLP!\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383,
          "referenced_widgets": [
            "9d3d7b4a1ea24ebaab6756931866789a",
            "eedc632ed39142b3a2447358bb2c3c80",
            "5c90498cc0e2445ab0b3614a14059f5a",
            "51666ce57c894bea96ee39771e7c4194",
            "244c6bf8c40940b19c8dfa0ce6fd9339",
            "e8bf23ef06d24fb09394d81accef58d7",
            "0e83d984231a4921b2659454fb66c687",
            "519f07e597b8453e807f6e1d53a415f6",
            "493ebf98725248a6a0e5bc5c39c4d583",
            "06a52b1e43824a7290892ac51fcdd73f",
            "218bb1c2d3a14c71810338171b7b2262",
            "1d64eee3ff284ec093943035bc144e1a",
            "00de109242e148559951bcd23cca1ed6",
            "d11ff2f2588d4d9fa2675d59aa7b186e",
            "9a4c7f4897fc434f90dc04901899fcce",
            "8f404be47a2f47fab7deb671168a305e",
            "1f776b021cf8413db5f20f3d79ac94c2",
            "c42c8d2e915a4b91b22cc7585c5b7bed",
            "404785b20a274dcea1a1f097f402a8c3",
            "adeb371cbaf3408e87c01ae2e4931bb3",
            "460da12d6f0d445bb504d783f34cdc58",
            "bd20a151997e4360939f2052671bf0bd",
            "4695a986969f4904b50e09be4ee16f8b",
            "aec877ccd67c42aa90e33ceba328b3c1",
            "5c6ee07db6de4dcdb2052121691731ab",
            "510cdd2720cf423d92b9b8059dbbd8ac",
            "394d681d259b4371bdcd0e4218e1818f",
            "fa8cfcb77c8442e5a78292bea35b99c5",
            "a7fdb3755dab4f5999fa9cebf0bc461e",
            "ce09994b95ba45dc9ddb1da823b65296",
            "95a3a129b8204d928f0b4798197f74ee",
            "bf4b43a366f74fda8d4fa8ab096b8711",
            "b042aba6f02e4ae9a17ca9ce9a1de944",
            "91648e5c1f8d4992a0a24adcefd9efce",
            "4db92588f41c449199e47d094b76245a",
            "a7e4be85d88641e7a26ffca934a1a9fc",
            "0a767f943fb446789b5acd4359ea11f8",
            "7b701fce331340d2990164e4b41b9f49",
            "71dde883326c48b88e13763526f533e9",
            "421360eb81e0437594f6c925bc8ccfd3",
            "601a7e38388149e29fafbe5f0d24eddd",
            "438b5f6acadd47988c371ea95bcac528",
            "d5f0dd1b65dc4ec1b63227a6a6e7ae25",
            "3a76a9e5fecb4a96948eb565160c0e66"
          ]
        },
        "id": "dLqUtbneNpV1",
        "outputId": "d699ea36-91ef-4507-f15a-39157f2b6cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d3d7b4a1ea24ebaab6756931866789a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d64eee3ff284ec093943035bc144e1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4695a986969f4904b50e09be4ee16f8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91648e5c1f8d4992a0a24adcefd9efce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9956631064414978}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try another sentence\n",
        "print(classifier(\"I hate this so much.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuVW1d9DN0oM",
        "outputId": "95f4de12-b761-4a8c-84fc-5eeccf47f2c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'NEGATIVE', 'score': 0.9995205402374268}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SECTION 5: Tokenization (How Transformers See Text)**"
      ],
      "metadata": {
        "id": "Vp2THOTAOAv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "Zw8EV2XHN-JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BERT tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "example = \"Transformers are powerful models.\"\n",
        "tokens = tokenizer.tokenize(example)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "083f5705b8ce4f14a5d8f97c42f7f988",
            "effaa6c1276f4dc990f970ae6fc798f6",
            "20c3a30bd9fc440bb9442be8fb9564ec",
            "65ed590f5712425fbc499a3f6aa002c8",
            "02eab649b0b44fa5ada07570176ccd9c",
            "1db1cfc2302d41718784f3c25014f719",
            "d5c9cc21a1be42f99c7fcbbae5a69d3f",
            "63be826e343a4d31b320efcf1e031209",
            "f0cdb2aa91864a1991f1613978c1d9eb",
            "5aad87a732cc47869d253e6e7000aa1b",
            "4c657affb7194645a7b462c39dae908a",
            "a54f6db0fbe146429017465c34c27632",
            "a9b1a501e33e488e95a43def53c9ed0d",
            "a71aae5eda8f4048872f68d0ba197141",
            "a34222e9d9d54f1d977ca38936b787d4",
            "40bc4d9606e04141a50455ce56c27479",
            "eea3e2b186ea45dbbb92d6a2e5020220",
            "3cfe94abdf994b4a981185ae64b00ced",
            "f11efeba942e428b842d18a1317b76dd",
            "1c03420a0396433582a0c98cfad28065",
            "63d26e2e3a9f413784da62085ea512e2",
            "744b6bde69674ef7b70d4fb76b1faaf0",
            "748c548d1c344c199a7ab2e3791b9b07",
            "6ad5d9fbfec249649016e6ae1852e2d3",
            "d57674304dc24c3db0fe9af6159dd7cc",
            "6d93572a37df4e4e9564b90cc6d7196a",
            "150e3d22dbd8442a8a1c9c23377ecbfe",
            "3f70811780a3478a81249a94aad6ad52",
            "0292864ce8ef4168b2b7af1e17731fec",
            "c2e89df937b74d5aae682b03e117fc1d",
            "e100bfa0f38f4ad7a50801318af814b9",
            "2d9515a504d342f8862853fdb978c50b",
            "3e8d03b5617848a8909511e6b9cfbcb2",
            "5356975363934475bddf62c89760503e",
            "37b5e490368a448696d23838be998fdc",
            "964b7ba6556a44aaa0ee505ae51998aa",
            "7c982afaa67b4513bc5a22b1d11c04c2",
            "8a974fd1875e432f94e403f11b9d8b84",
            "3b192b74be1a46ababd62816820ef6bb",
            "55d819d38f8e416dada8cb6744704258",
            "b646b9d95ea845c5ac5ffb9b552c1004",
            "3aff440cc6e54f45b4b3c97689efa0bd",
            "8c5f3991074d4a4e830a0bcf725efbd8",
            "efa506d2126840a3a1fe5eb5e47cd69e"
          ]
        },
        "id": "sSXE-PlDOD1d",
        "outputId": "bd52864e-12d0-4b17-e363-b3a451d466cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "083f5705b8ce4f14a5d8f97c42f7f988"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a54f6db0fbe146429017465c34c27632"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "748c548d1c344c199a7ab2e3791b9b07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5356975363934475bddf62c89760503e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tokens:\", tokens)\n",
        "print(\"Token IDs:\", ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI4JJ_RiOGh3",
        "outputId": "7d792c59-4a61-4c0d-9f25-6ef98ae766e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['transformers', 'are', 'powerful', 'models', '.']\n",
            "Token IDs: [19081, 2024, 3928, 4275, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## üîç Real-World Use Cases of BERT\n",
        "\n",
        "| Task                      | Description                                      |\n",
        "|---------------------------|--------------------------------------------------|\n",
        "| Sentiment Classification  | Predict sentiment from reviews                   |\n",
        "| Named Entity Recognition  | Identify names, places, etc.                     |\n",
        "| Question Answering        | Extract answers from passages                    |\n",
        "| Semantic Similarity       | Compare sentence meanings                        |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "3ZmygYTFPuRg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Concept Check: BERT vs GPT\n",
        "|Aspect             | BERT               | GPT\n",
        "|-------------------|--------------------|-------------------------\n",
        "|Direction          | Bidirectional      | Left-to-right\n",
        "|Training Objective | MLM + NSP          | Next token prediction\n",
        "|Strengths          | Classification, QA | Text generation"
      ],
      "metadata": {
        "id": "0hE08e6IQCfK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìò Summary\n",
        "Transformers changed NLP forever:\n",
        "\n",
        "- BERT ‚Üí bidirectional understanding of language\n",
        "\n",
        "- Hugging Face ‚Üí makes it super easy to use\n",
        "\n",
        "- One model can solve many tasks\n",
        "\n"
      ],
      "metadata": {
        "id": "uV1iFbYkQuVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SECTION 6: Fine-Tuning BERT (on Custom Dataset - Optional)**"
      ],
      "metadata": {
        "id": "Miu3iQG3OMf2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß™ Want to Go Further?\n",
        "Use `Trainer` or `AutoModelForSequenceClassification` from Hugging Face\n",
        "and fine-tune BERT on your own text classification dataset üöÄ\n",
        "\n",
        "We'll revisit this in the capstone projects."
      ],
      "metadata": {
        "id": "QJ2xy4HUOOo3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SECTION 7: Exercises**"
      ],
      "metadata": {
        "id": "Rt5ogJaWOQzv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìù Exercises:\n",
        "1. Try the `zero-shot-classification` pipeline.\n",
        "2. Tokenize a custom sentence and decode the IDs.\n",
        "3. Use `AutoModel` and `AutoTokenizer` to extract embeddings.\n",
        "4. Read BERT's original paper or Hugging Face docs."
      ],
      "metadata": {
        "id": "WAvMPYKfOTSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üëã Next week**: We'll explore modern **NLP architectures like T5 and BART** ‚Äî powerful encoder-decoder models for summarization, rephrasing, and generation!"
      ],
      "metadata": {
        "id": "NEEvL8MvQ2Zu"
      }
    }
  ]
}